{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data come from the video game FIFA and have 10 variables of 7917 soccer players. The variables include: position, rating, height, foot, pace, shooting, passing, dribbling, defending, and heading. Here we want to predict a player's position. Position has three categories: defender, midfielder and forward (0, 1, and 2). Foot is binary, either left or right (0 or 1). Other attributes are ratings between 0 and 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7917, 10)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "players = np.genfromtxt('/Users/linggeli/random/players.csv', delimiter=',', skip_header=1)\n",
    "print(players.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[  0.  94. 169.   0.  93.  87.  82.  97.  46.  67.]\n",
      " [  0.  92. 186.   1.  92.  90.  79.  93.  59.  89.]\n",
      " [  2.  92. 170.   1.  67.  72.  92.  85.  68.  53.]\n",
      " [  2.  91. 170.   1.  78.  72.  90.  91.  65.  55.]\n",
      " [  0.  90. 177.   1.  83.  88.  79.  84.  71.  81.]]\n"
     ]
    }
   ],
   "source": [
    "# first 5 rows of the data\n",
    "print(players[:5, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since this is a multi-label classification problem, we prepare the data by taking the first column (position) and turning it into a binary matrix where position of 1 indicates true label. This process is also known as one-hot encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# one-hot encode\n",
    "target = np.zeros((players.shape[0], 3))\n",
    "target[np.arange(target.shape[0]), players[:, 0].astype(int)] = 1\n",
    "dataY = target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Centering and scaling quantitative data to mean 0 and standard deviation 1 is a common method of pre-processing, increasing numerical numerical stability and convergence rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 3.84772723 -1.93378785  0.          2.2443199   2.43204138  2.11237344\n",
      "   2.92187769 -1.34994179  0.36257204]\n",
      " [ 3.56511793  0.80828486  1.          2.15478325  2.66043381  1.83868468\n",
      "   2.59546665 -0.12610444  2.81188449]\n",
      " [ 3.56511793 -1.77248945  1.         -0.08363314  1.29007923  3.02466932\n",
      "   1.94264457  0.72116757 -1.19608133]\n",
      " [ 3.42381328 -1.77248945  1.          0.90127007  1.29007923  2.84221014\n",
      "   2.43226113  0.43874357 -0.97341656]\n",
      " [ 3.28250863 -0.64340069  1.          1.34895335  2.50817219  1.83868468\n",
      "   1.86104181  1.00359158  1.92122542]]\n"
     ]
    }
   ],
   "source": [
    "dataX = players[:, 1:]\n",
    "for i in range(9):\n",
    "    if i != 2:\n",
    "        dataX[:, i] = (dataX[:, i] - np.mean(dataX[:, i])) / np.std(dataX[:, i])\n",
    "print(dataX[:5, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7917, 9)\n"
     ]
    }
   ],
   "source": [
    "N, D = dataX.shape\n",
    "print(N, D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the data into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_size = int(N * 0.1)\n",
    "test_size = N - train_size\n",
    "rand_ind = np.random.permutation(N) # shuffle the row indices\n",
    "train_ind = rand_ind[:train_size]\n",
    "test_ind = rand_ind[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = dataX[train_ind, :]\n",
    "X_test = dataX[test_ind, :]\n",
    "y_train = dataY[train_ind, :]\n",
    "y_test = dataY[test_ind, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(791, 3)\n",
      "(7126, 3)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = tf.placeholder(\"float\", shape=[None, D])\n",
    "y = tf.placeholder(\"float\", shape=[None, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**\n",
    "How would you change the activation function?\n",
    "How would you change the number of neurons?\n",
    "How would you add more layers?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# first hidden layer\n",
    "W1 = tf.Variable(tf.random_normal([D, 50], stddev=1.0))\n",
    "b1 = tf.Variable(tf.random_normal([1, 50], stddev=1.0))\n",
    "h1 = tf.nn.sigmoid(tf.matmul(X, W1) + b1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# output layer\n",
    "W2 = tf.Variable(tf.random_normal([50, 3], stddev=1.0))\n",
    "b2 = tf.Variable(tf.random_normal([1, 3], stddev=1.0))\n",
    "yhat = tf.nn.sigmoid(tf.matmul(h1, W2) + b2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Multi-label classification loss function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(labels=y, logits=yhat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    Calculate multi-label classification accuracy.\n",
    "    \n",
    "    Args\n",
    "        y_true: (2d numpy array) [n_example, n_label]\n",
    "        y_pred: (2d numpy array) [n_example, n_label]\n",
    "    \"\"\"\n",
    "    return(np.mean(y_true.argmax(axis=-1) == y_hat.argmax(axis=-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Stochastic gradient descent**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "step_size = 1.0\n",
    "\n",
    "n_epochs = 100\n",
    "n_batch = y_train.shape[0] / batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "updates = tf.train.GradientDescentOptimizer(step_size).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with tf.Session() as sess:\n",
    "    tf.global_variables_initializer().run()\n",
    "    for k in range(n_epochs):\n",
    "        for i in range(0, n_batch):\n",
    "            # generate batch data\n",
    "            offset = (i * batch_size) % (y_train.shape[0] - batch_size)\n",
    "            batch_data = X_train[offset:(offset + batch_size), :]\n",
    "            batch_labels = y_train[offset:(offset + batch_size), :]\n",
    "            # stochastic gradient descent\n",
    "            sess.run(updates, feed_dict={X: batch_data, y: batch_labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
